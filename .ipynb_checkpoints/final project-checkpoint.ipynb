{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Final Project\n",
    "\n",
    "Bill Tang, Lini Tan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data processing\n",
    "1. firstly, we deal with the missing data. we convert all missing data (indicated by a ?) into NaN, and to add the appropriate column names (BI_RADS, age, shape, margin, density, and severity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>age</th>\n",
       "      <th>shape</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BI-RADS   age  shape  margin  density  severity\n",
       "0      5.0  67.0    3.0     5.0      3.0         1\n",
       "1      4.0  43.0    1.0     1.0      NaN         1\n",
       "2      5.0  58.0    4.0     5.0      3.0         1\n",
       "3      4.0  28.0    1.0     1.0      3.0         0\n",
       "4      5.0  74.0    1.0     5.0      NaN         1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "masses_data = pd.read_csv('data.txt')\n",
    "masses_data = pd.read_csv('data.txt', na_values=['?'], names = ['BI-RADS', 'age', 'shape', 'margin', 'density', 'severity'])\n",
    "masses_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>age</th>\n",
       "      <th>shape</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>959.000000</td>\n",
       "      <td>956.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>913.000000</td>\n",
       "      <td>885.000000</td>\n",
       "      <td>961.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.348279</td>\n",
       "      <td>55.487448</td>\n",
       "      <td>2.721505</td>\n",
       "      <td>2.796276</td>\n",
       "      <td>2.910734</td>\n",
       "      <td>0.463059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.783031</td>\n",
       "      <td>14.480131</td>\n",
       "      <td>1.242792</td>\n",
       "      <td>1.566546</td>\n",
       "      <td>0.380444</td>\n",
       "      <td>0.498893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BI-RADS         age       shape      margin     density    severity\n",
       "count  959.000000  956.000000  930.000000  913.000000  885.000000  961.000000\n",
       "mean     4.348279   55.487448    2.721505    2.796276    2.910734    0.463059\n",
       "std      1.783031   14.480131    1.242792    1.566546    0.380444    0.498893\n",
       "min      0.000000   18.000000    1.000000    1.000000    1.000000    0.000000\n",
       "25%      4.000000   45.000000    2.000000    1.000000    3.000000    0.000000\n",
       "50%      4.000000   57.000000    3.000000    3.000000    3.000000    0.000000\n",
       "75%      5.000000   66.000000    4.000000    4.000000    3.000000    1.000000\n",
       "max     55.000000   96.000000    4.000000    5.000000    4.000000    1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masses_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Before we just drop every row that's missing data, we have to make sure how those missing data distribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>age</th>\n",
       "      <th>shape</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>5.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>5.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>5.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>5.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>3.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>4.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>4.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>4.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>4.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>4.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>6.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BI-RADS   age  shape  margin  density  severity\n",
       "1        4.0  43.0    1.0     1.0      NaN         1\n",
       "4        5.0  74.0    1.0     5.0      NaN         1\n",
       "5        4.0  65.0    1.0     NaN      3.0         0\n",
       "6        4.0  70.0    NaN     NaN      3.0         0\n",
       "7        5.0  42.0    1.0     NaN      3.0         0\n",
       "9        5.0  60.0    NaN     5.0      1.0         1\n",
       "12       4.0  64.0    1.0     NaN      3.0         0\n",
       "19       4.0  40.0    1.0     NaN      NaN         0\n",
       "20       NaN  66.0    NaN     NaN      1.0         1\n",
       "22       4.0  43.0    1.0     NaN      NaN         0\n",
       "26       2.0  66.0    1.0     1.0      NaN         0\n",
       "27       5.0  63.0    3.0     NaN      3.0         0\n",
       "35       4.0  77.0    3.0     NaN      NaN         0\n",
       "38       4.0  48.0    4.0     5.0      NaN         1\n",
       "40       4.0  59.0    2.0     1.0      NaN         0\n",
       "43       4.0  61.0    2.0     1.0      NaN         0\n",
       "45       5.0  44.0    2.0     4.0      NaN         1\n",
       "47       4.0  23.0    1.0     1.0      NaN         0\n",
       "48       2.0  42.0    NaN     NaN      4.0         0\n",
       "52       4.0  23.0    1.0     1.0      NaN         0\n",
       "53       4.0  63.0    2.0     1.0      NaN         0\n",
       "54       4.0  53.0    NaN     5.0      3.0         1\n",
       "55       4.0  43.0    3.0     4.0      NaN         0\n",
       "57       5.0  51.0    2.0     4.0      NaN         0\n",
       "58       4.0  45.0    2.0     1.0      NaN         0\n",
       "59       5.0  59.0    2.0     NaN      NaN         1\n",
       "63       3.0  57.0    2.0     1.0      NaN         0\n",
       "65       4.0  25.0    2.0     1.0      NaN         0\n",
       "67       5.0  72.0    4.0     3.0      NaN         1\n",
       "74       5.0  70.0    NaN     4.0      NaN         1\n",
       "..       ...   ...    ...     ...      ...       ...\n",
       "496      4.0  82.0    NaN     5.0      3.0         1\n",
       "501      5.0  59.0    4.0     4.0      NaN         1\n",
       "519      3.0  68.0    NaN     NaN      3.0         0\n",
       "520      4.0  62.0    4.0     NaN      3.0         1\n",
       "521      5.0  65.0    1.0     NaN      3.0         1\n",
       "531      4.0  55.0    NaN     NaN      3.0         0\n",
       "537      5.0  63.0    NaN     4.0      3.0         1\n",
       "541      4.0  49.0    2.0     NaN      3.0         0\n",
       "554      5.0  70.0    NaN     5.0      3.0         1\n",
       "561      2.0  59.0    NaN     4.0      3.0         0\n",
       "569      4.0  64.0    3.0     4.0      NaN         1\n",
       "574      4.0  60.0    3.0     NaN      NaN         0\n",
       "581      2.0  65.0    NaN     1.0      2.0         0\n",
       "614      3.0  46.0    NaN     5.0      NaN         1\n",
       "627      4.0  57.0    2.0     1.0      NaN         0\n",
       "660      4.0  58.0    NaN     4.0      3.0         1\n",
       "661      4.0  51.0    NaN     4.0      3.0         0\n",
       "662      3.0  50.0    NaN     NaN      3.0         1\n",
       "665      4.0  27.0    2.0     1.0      NaN         0\n",
       "677      4.0  57.0    4.0     4.0      NaN         1\n",
       "683      5.0   NaN    3.0     3.0      3.0         1\n",
       "691      4.0  72.0    3.0     NaN      3.0         0\n",
       "723      4.0  60.0    3.0     NaN      4.0         0\n",
       "745      6.0  76.0    3.0     NaN      3.0         0\n",
       "752      5.0  48.0    NaN     4.0      NaN         1\n",
       "778      4.0  60.0    NaN     4.0      3.0         0\n",
       "819      4.0  35.0    3.0     NaN      2.0         0\n",
       "824      6.0  40.0    NaN     3.0      4.0         1\n",
       "884      5.0   NaN    4.0     4.0      3.0         1\n",
       "923      5.0   NaN    4.0     3.0      3.0         1\n",
       "\n",
       "[130 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masses_data.loc[(masses_data['age'].isnull()) |\n",
    "              (masses_data['shape'].isnull()) |\n",
    "              (masses_data['margin'].isnull()) |\n",
    "              (masses_data['density'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The missing data seems randomly distributed, so we drop the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>age</th>\n",
       "      <th>shape</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.393976</td>\n",
       "      <td>55.781928</td>\n",
       "      <td>2.781928</td>\n",
       "      <td>2.813253</td>\n",
       "      <td>2.915663</td>\n",
       "      <td>0.485542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.888371</td>\n",
       "      <td>14.671782</td>\n",
       "      <td>1.242361</td>\n",
       "      <td>1.567175</td>\n",
       "      <td>0.350936</td>\n",
       "      <td>0.500092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BI-RADS         age       shape      margin     density    severity\n",
       "count  830.000000  830.000000  830.000000  830.000000  830.000000  830.000000\n",
       "mean     4.393976   55.781928    2.781928    2.813253    2.915663    0.485542\n",
       "std      1.888371   14.671782    1.242361    1.567175    0.350936    0.500092\n",
       "min      0.000000   18.000000    1.000000    1.000000    1.000000    0.000000\n",
       "25%      4.000000   46.000000    2.000000    1.000000    3.000000    0.000000\n",
       "50%      4.000000   57.000000    3.000000    3.000000    3.000000    0.000000\n",
       "75%      5.000000   66.000000    4.000000    4.000000    3.000000    1.000000\n",
       "max     55.000000   96.000000    4.000000    5.000000    4.000000    1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masses_data.dropna(inplace=True)\n",
    "masses_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we convert the Pandas dataframes into numpy arrays that can be used by scikit_learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 67.,   3.,   5.,   3.],\n",
       "       [ 58.,   4.,   5.,   3.],\n",
       "       [ 28.,   1.,   1.,   3.],\n",
       "       ..., \n",
       "       [ 64.,   4.,   5.,   3.],\n",
       "       [ 66.,   4.,   5.,   3.],\n",
       "       [ 62.,   3.,   3.,   3.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = masses_data[['age', 'shape',\n",
    "                             'margin', 'density']].values\n",
    "\n",
    "\n",
    "all_classes = masses_data['severity'].values\n",
    "\n",
    "feature_names = ['age', 'shape', 'margin', 'density']\n",
    "\n",
    "all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Normalize the attribute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7650629 ,  0.17563638,  1.39618483,  0.24046607],\n",
       "       [ 0.15127063,  0.98104077,  1.39618483,  0.24046607],\n",
       "       [-1.89470363, -1.43517241, -1.157718  ,  0.24046607],\n",
       "       ..., \n",
       "       [ 0.56046548,  0.98104077,  1.39618483,  0.24046607],\n",
       "       [ 0.69686376,  0.98104077,  1.39618483,  0.24046607],\n",
       "       [ 0.42406719,  0.17563638,  0.11923341,  0.24046607]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "all_features_scaled = scaler.fit_transform(all_features)\n",
    "all_features_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data analyze\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "Before moving to K-Fold cross validation and random forests, start by creating a single train/test split of our data. Set aside 75% for training, and 25% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "\n",
    "(training_inputs,\n",
    " testing_inputs,\n",
    " training_classes,\n",
    " testing_classes) = train_test_split(all_features_scaled, all_classes, train_size=0.75, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now create a DecisionTreeClassifier and fit it to your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf= DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "clf.fit(training_inputs, training_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Display the resulting decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b1b4c772a89e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                          feature_names=feature_names)  \n\u001b[1;32m      9\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/tanlini/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, prog)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             self.__setattr__(\n\u001b[1;32m   1796\u001b[0m                 \u001b[0;34m'create_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m                 \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m             )\n\u001b[1;32m   1799\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tanlini/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[0;32m-> 1960\u001b[0;31m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[1;32m   1961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn import tree\n",
    "from pydotplus import graph_from_dot_data \n",
    "\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(clf, out_file=dot_data,  \n",
    "                         feature_names=feature_names)  \n",
    "graph = graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Measure the accuracy of the resulting decision tree model using your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.score(testing_inputs, testing_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now instead of a single train/test split, use K-Fold cross validation to get a better measure of your model's accuracy (K=10). Hint: use model_selection.cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "cv_scores = cross_val_score(clf, all_features_scaled, all_classes, cv=10)\n",
    "\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now try a RandomForestClassifier instead. Does it perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-56b7f505b5c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_features_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tanlini/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/sklearn/ensemble/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbagging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaggingRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0miforest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mweight_boosting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mweight_boosting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdaBoostRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgradient_boosting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tanlini/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumath_tests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minner1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEnsemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "cv_scores = cross_val_score(clf, all_features_scaled, all_classes, cv=10)\n",
    "\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78547954885745075"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "cv_scores = cross_val_score(clf, all_features_scaled, all_classes, cv=10)\n",
    "\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Choosing K is tricky, so we write a for loop to run KNN with K values ranging from 1 to 50 and see if K makes a substantial difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.723912374236\n",
      "2 0.688983809804\n",
      "3 0.75410806991\n",
      "4 0.730081300813\n",
      "5 0.773546450611\n",
      "6 0.762616318934\n",
      "7 0.794059513315\n",
      "8 0.774708240628\n",
      "9 0.788020024348\n",
      "10 0.785479548857\n",
      "11 0.79153338091\n",
      "12 0.779425716805\n",
      "13 0.781908470117\n",
      "14 0.791503995074\n",
      "15 0.787874844325\n",
      "16 0.779441109385\n",
      "17 0.781807368848\n",
      "18 0.775681121699\n",
      "19 0.780514741894\n",
      "20 0.782866658271\n",
      "21 0.785392790675\n",
      "22 0.78173425409\n",
      "23 0.780558820648\n",
      "24 0.780587506822\n",
      "25 0.787817122147\n",
      "26 0.786626995788\n",
      "27 0.785436519598\n",
      "28 0.790227110533\n",
      "29 0.786597959783\n",
      "30 0.787831465234\n",
      "31 0.791417236892\n",
      "32 0.787831465234\n",
      "33 0.786597609952\n",
      "34 0.786611953039\n",
      "35 0.786626296125\n",
      "36 0.785435819935\n",
      "37 0.786684368135\n",
      "38 0.78665533213\n",
      "39 0.787889187412\n",
      "40 0.785479199026\n",
      "41 0.785464506108\n",
      "42 0.781850048277\n",
      "43 0.78306921064\n",
      "44 0.783054867554\n",
      "45 0.783054867554\n",
      "46 0.785464855939\n",
      "47 0.786684368135\n",
      "48 0.789065320516\n",
      "49 0.790299525629\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, 50):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=n)\n",
    "    cv_scores = cross_val_score(clf, all_features_scaled, all_classes, cv=10)\n",
    "    print (n, cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Now try naive_bayes.MultinomialNB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78440556651693882"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "all_features_minmax = scaler.fit_transform(all_features)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "cv_scores = cross_val_score(clf, all_features_minmax, all_classes, cv=10)\n",
    "\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80735835327372207"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "cv_scores = cross_val_score(lr, all_features_scaled, all_classes, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAF5CAYAAAAS3BpAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12663d748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "X, y = make_classification(200, 2, 2, 0, weights=[.5, .5], random_state=15)\n",
    "clf = LogisticRegression().fit(X[:100], y[:100])\n",
    "xx, yy = np.mgrid[-5:5:.01, -5:5:.01]\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "probs = clf.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\",\n",
    "                      vmin=0, vmax=1)\n",
    "ax_c = f.colorbar(contour)\n",
    "ax_c.set_label(\"$P(y = 1)$\")\n",
    "ax_c.set_ticks([0, .25, .5, .75, 1])\n",
    "\n",
    "ax.scatter(X[100:,0], X[100:, 1], c=y[100:], s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "ax.set(aspect=\"equal\",\n",
    "       xlim=(-5, 5), ylim=(-5, 5),\n",
    "       xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural Networks\n",
    "\n",
    "Lastly, we use nerual networks. we use Keras to set up a neural network with 1 binary output neuron and see how it performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    #4 feature inputs going into an 7-unit layer \n",
    "    model.add(Dense(7, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "    # \"Deep learning\" turns out to be unnecessary - this additional hidden layer doesn't help either.\n",
    "    #model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    # Output layer with a binary classification (benign or malignant)\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model; rmsprop seemed to work best\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73253012051783417"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Wrap our Keras model in an estimator compatible with scikit_learn\n",
    "estimator = KerasClassifier(build_fn=create_model, nb_epoch=100, verbose=0)\n",
    "# Now we can use scikit_learn's cross_val_score to evaluate this model identically to the others\n",
    "cv_scores = cross_val_score(estimator, all_features_scaled, all_classes, cv=10)\n",
    "cv_scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_neural_net(ax, left, right, bottom, top, layer_sizes):\n",
    "    '''\n",
    "    Draw a neural network cartoon using matplotilb.\n",
    "    \n",
    "    :usage:\n",
    "        >>> fig = plt.figure(figsize=(12, 12))\n",
    "        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])\n",
    "    \n",
    "    :parameters:\n",
    "        - ax : matplotlib.axes.AxesSubplot\n",
    "            The axes on which to plot the cartoon (get e.g. by plt.gca())\n",
    "        - left : float\n",
    "            The center of the leftmost node(s) will be placed here\n",
    "        - right : float\n",
    "            The center of the rightmost node(s) will be placed here\n",
    "        - bottom : float\n",
    "            The center of the bottommost node(s) will be placed here\n",
    "        - top : float\n",
    "            The center of the topmost node(s) will be placed here\n",
    "        - layer_sizes : list of int\n",
    "            List of layer sizes, including input and output dimensionality\n",
    "    '''\n",
    "    n_layers = len(layer_sizes)\n",
    "    v_spacing = (top - bottom)/float(max(layer_sizes))\n",
    "    h_spacing = (right - left)/float(len(layer_sizes) - 1)\n",
    "    # Nodes\n",
    "    for n, layer_size in enumerate(layer_sizes):\n",
    "        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.\n",
    "        for m in xrange(layer_size):\n",
    "            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,\n",
    "                                color='w', ec='k', zorder=4)\n",
    "            ax.add_artist(circle)\n",
    "    # Edges\n",
    "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
    "        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
    "        for m in xrange(layer_size_a):\n",
    "            for o in xrange(layer_size_b):\n",
    "                line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],\n",
    "                                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')\n",
    "                ax.add_artist(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-1f142fe47772>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdraw_neural_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-8297da49da05>\u001b[0m in \u001b[0;36mdraw_neural_net\u001b[0;34m(ax, left, right, bottom, top, layer_sizes)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mlayer_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_spacing\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,\n\u001b[1;32m     33\u001b[0m                                 color='w', ec='k', zorder=4)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.gca()\n",
    "ax.axis('off')\n",
    "draw_neural_net(ax, .1, .9, .1, .9, [4, 7, 2])\n",
    "fig.savefig('nn.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### In this study, decision tree performs the worst. The logistic regression performs the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
