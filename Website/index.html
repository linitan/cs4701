
<!DOCTYPE html>
<!--[if lt IE 7]>      <html lang="en" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html lang="en" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html lang="en" class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
    <head>
    	<!-- meta character set -->
        <meta charset="utf-8">
		<!-- Always force latest IE rendering engine or request Chrome Frame -->
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>CS 4701 Final project</title>
		<!-- Meta Description -->
        <meta name="description" content="cs4701 final presentation">
        <meta name="keywords" content="Artificial-Intelligence Medical-Care">
        <meta name="author" content="Lini Tan, Bill Tang">

		<!-- Mobile Specific Meta -->
        <meta name="viewport" content="width=device-width, initial-scale=1">

		<!-- CSS
		================================================== -->

		<link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300,700' rel='stylesheet' type='text/css'>

		<!-- Fontawesome Icon font -->
        <link rel="stylesheet" href="css/font-awesome.min.css">
		<!-- bootstrap.min -->
        <link rel="stylesheet" href="css/jquery.fancybox.css">
		<!-- bootstrap.min -->
        <link rel="stylesheet" href="css/bootstrap.min.css">
		<!-- bootstrap.min -->
        <link rel="stylesheet" href="css/owl.carousel.css">
		<!-- bootstrap.min -->
        <link rel="stylesheet" href="css/slit-slider.css">
		<!-- bootstrap.min -->
        <link rel="stylesheet" href="css/animate.css">
		<!-- Main Stylesheet -->
        <link rel="stylesheet" href="css/main.css">

		<!-- Modernizer Script for old Browsers -->
		<script src="js/modernizr-2.6.2.min.js"></script>
	

    </head>

    <body id="body">

		<!-- preloader -->
		<div id="preloader">
            <div class="loder-box">
            	<div class="battery"></div>
            </div>
		</div>
		<!-- end preloader -->

        <!--
        Fixed Navigation
        ==================================== -->
        <header id="navigation" class="navbar-inverse navbar-fixed-top animated-header">
            <div class="container">
                <div class="navbar-header">
                    <!-- responsive nav button -->
					<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
						<span class="sr-only">Toggle navigation</span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
                    </button>
					<!-- /responsive nav button -->


					<!-- /logo -->
                </div>

				<!-- main nav -->
                <nav class="collapse navbar-collapse navbar-right" role="navigation">
                    <ul id="nav" class="nav navbar-nav">
                        <li><a href="#body">Home</a></li>
                        <li><a href="#about">About Us</a></li>
                        <li><a href="#method">Method Introduction</a></li>
                        <li><a href="#portfolio">Case Study</a></li>
                        <li><a href="#service">Real-world Practice</a></li>
                        <li><a href="#testimonials">Conclusion</a></li>
                    </ul>
                </nav>
				<!-- /main nav -->

            </div>
        </header>
        <!--
        End Fixed Navigation
        ==================================== -->

		<main class="site-content" role="main">

        <!--
        Home Slider
        ==================================== -->

		<section id="home-slider">
            <div id="slider" class="sl-slider-wrapper">

				<div class="sl-slider">

					<div class="sl-slide" data-orientation="horizontal" data-slice1-rotation="-25" data-slice2-rotation="-25" data-slice1-scale="2" data-slice2-scale="2">

						<div class="bg-img bg-img-1"></div>

						<div class="slide-caption">
                            <div class="caption-content">
                                <h2 class="animated fadeInDown">Ensemble Learning in Diagnosing Cancer
								</h2>
                                <span class="animated fadeInDown">Introduce the basic analytical method and real world practise</span>
                                <!-- <a href="#" class="btn btn-blue btn-effect">Join US</a> -->
                            </div>
                        </div>

					</div>


				</div><!-- /sl-slider -->

			</div><!-- /slider-wrapper -->
		</section>

        <!--
        End Home SliderEnd
        ==================================== -->

			<!-- about section -->
			<section id="about" >
				<div class="container">
					<div class="row">
            <div class="col-md-11 col-md-offset-1 wow animated fadeInLeft">
							<div class="welcome-block">
								<h3>Welcome To Our Site</h3>
						     	 <div class="message-body">
									<img src="img/member-1.jpg" class="pull-left" alt="member">
						       		<p class="wow animated">Hello, This is Bill and Lini! This is our website for the Course CS4701 Practicum in Artificial Intelligence.</p>
                      <p>
						The emergence of our thought on diagnosing breast cancer with machine learning method comes from Professor Bart, who taught Artificial intelligence at Cornell University. In 2017 fall, lecture slide 13, he mentioned how Decision Tree surpassed human experts and has been successfully diagnosing breast cancer. Out of curiosity, we wondered two questions: Why Decision Tree not other machine learning models is used? Is there a better machine learning technique that results the better prediction? 
						Following curiosity about this two questions, we conducted this case study.  In this website, we will first briefly introduce each method we used.  Then, we demonstrate the test methods followed by test results. In the end, we will compare the results from different method, and make a conclusion based on the results.  
						
					</p>
						     	 </div>
						    </div>
						</div>
					</div>
				</div>
			</section>
			<!-- end about section -->


			<!-- method section -->
			<section id="method">
				<div class="container">
					<div class="row">

						<div class="sec-title text-center wow animated fadeInDown">
							<h2>Method Introduction</h2>
							<p>Take a sip of deep learning. We introduce six basic deep learning methods</p>
						</div>


						<ul class="project-wrapper wow animated fadeInUp">
							<li class="portfolio-item">
								<img src="img/portfolio/item.jpg" class="img-responsive" 
								alt="Decision Tree, a form of supervised learning, is widely used to support making decisions by generating a tree-like graph. 
								The decision tree is very natural to human. A decision is made by walking down the tree from the root. At each level, a decision node specifies a choice of some attribute with two or more alternatives. Every decision node is part of a path to a leaf node which indicates the classification of a data set. 
								To construct a Decision Tree consistent with the training example, Decision Tree learning algorithm is used. The idea is to recursively choose the most significant attribute as root, and then use a top-down greedy search through the space of possible Decision Tree. The significance of the attribute is determined by something called “Information Gain” which is calculated by using the concept of “Information Entropy”.								
								">
								<figcaption class="mask">
									<h3>Decision Tree</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="Decision Tree" data-fancybox-group="works" href="img/portfolio/iteml.jpg"><i class="fa fa-search"></i></a></li>
									<li><a href="https://en.wikipedia.org/wiki/Decision_tree" target="_blank"><i class="fa fa-link"></i></a></li>
								</ul>
							</li>

							<li class="portfolio-item">
								<img src="img/portfolio/item2.jpg" class="img-responsive" 
								alt="Similar to decision tree, a Random Forest algorithm is a supervised classification algorithm working as a large collection of decorrelated decision trees. Instead of only one tree as with Decision Tree, many Decision Trees are used in Random Forest Algorithm. Also, instead of using information gain and gini index for calculating the root node, finding the root node and splitting the feature nodes will be randomized. 
								To construct a Random Forest from a sample, the concept of bagging is used. The bagging is to average noisy and unbiased models in order to create a model with low variance.  The basic idea is to divide the sample into M subsets, and then create M decision trees with the corresponding data using Random Forest Algorithm. 
								To make a decision using Random Forest, an instance is feed into the root of each sub-decision tree. Sub-trees will then produce classifications from each one of them. The final prediction is based on majority voting among the classifications of Decision Trees. 
								
								">
								<figcaption class="mask">
									<h3>Random Forest</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="Random Forest" href="img/portfolio/item2l.jpg" data-fancybox-group="works" ><i class="fa fa-search"></i></a></li>
									<li><a href="https://en.wikipedia.org/wiki/Random_forest" target="_blank"><i class="fa fa-link"></i></a></li>
								</ul>
							</li>

							<li class="portfolio-item">
								<img src="img/portfolio/item3.jpg" class="img-responsive" 
								alt="The k-nearest neighbors algorithm is a supervised learning, non-parametric method used for classification. The idea of clustering is used to group a set of objects in a way that objects in the same group are more similar to each other than those in other groups. 
								In k-NN algorithm, the classification of a new data point is based on the “distance metric” to k nearest neighbors in the training data set. Then, this new object is classified by a majority vote of its neighbors.
								Correctly choosing the k factor determines the total accuracy of such algorithm. To gain optimal value of k, we can segregate the training set and validation set from the initial data set. Then, plot the validation error curve to obtain the optimal value of k at the minimal error point. 								
								">
								<figcaption class="mask">
									<h3>KNN algorithms</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="KNN algorithms" data-fancybox-group="works" href="img/portfolio/item3l.jpg"><i class="fa fa-search"></i></a></li>
									<li><a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" target="_blank"><i class="fa fa-link"></i></a></li>
								</ul>
							</li>

							<li class="portfolio-item">
								<img src="img/portfolio/item4.jpg" class="img-responsive" 
								alt="In machine learning, Naïve Bayes method forms a group of simple probabilistic classifiers by applying Bayes’ theorem with strong independence assumptions between the features.
								Given a small set of training data, Naïve Bayes classifiers can be trained very efficiently in a supervised learning setting. To estimate the parameters for naïve Bayes models, the idea of maximum likelihood is used, meaning one can work with the naïve Bayes model without accepting Bayesian probability or applying Bayesian methods.								
								">
								<figcaption class="mask">
									<h3>Naive Bayes</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="Naive Bayes" data-fancybox-group="works" href="img/portfolio/item4l.jpg"><i class="fa fa-search"></i></a></li>
									<li><a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" target="_blank"><i class="fa fa-link"></i></a></li>
								</ul>
							</li>

							<li class="portfolio-item">
								<img src="img/portfolio/item5.jpg" class="img-responsive" 
								alt="Logistic regression was developed by David Cox, which is used to estimate the probability of a binary response based on one or more predictor variables. In the regression model, the dependent variable is categorical. It allows one today that the presence of a risk factor increases the odds of a given outcome by a specific factor.
								The logistic regression is simple to implement and easy to compute.  However, the decision boundary has to be linear (i.e. separable by a hyperplane). It could also end up being a feature selection problem as well. This is the problem we need to consider when using logistic regression.								
								">
								<figcaption class="mask">
									<h3>Logistic Regression</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="Logistic Regression" data-fancybox-group="works" href="img/portfolio/item5l.jpg"><i class="fa fa-search"></i></a></li>
									<li><a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank"><i class="fa fa-link"></i></a></li>
								</ul>
							</li>

							<li class="portfolio-item">
								<img src="img/portfolio/item6.jpg" class="img-responsive" 
								alt="Artificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve performance on) tasks by considering examples, generally without task-specific programming.
								To construct a neural network, we consider it as a collection of connected units called artificial neurons. Each connection between neurons can transmit a signal from one to another. The receiving neuron can process the signals and then signal neurons connected to it.
								In order to learn multi-layer neural nets, we consider the backpropagation algorithm for training such networks.								
								">
								<figcaption class="mask">
									<h3>Neural Network</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="Neural Network" data-fancybox-group="works" href="img/portfolio/item6l.jpg"><i class="fa fa-search"></i></a></li>
									<li><a href="https://en.wikipedia.org/wiki/Artificial_neural_network" target="_blank"><i class="fa fa-link"></i></a></li>
								</ul>
							</li>
						</ul>

					</div>
				</div>
			</section>
			<!-- end Service section -->

			<!-- portfolio section -->
			<section id="portfolio">
				<div class="container">
					<div class="row">

						<div class="sec-title text-center wow animated fadeInDown">
							<h2>Case Study</h2>
							<p>
								To answer two questions mentioned in the introduction of this report, we first searched raw data on Machine Learning Repository. We obtained the Mammographic Mass Data Set which is published by Image Processing and Medical Engineering from Fraunhofer Institute for Integrated Circuits in Germany. 
								Our goal is to apply six machine learning models to this data, and measure the success of 
								results based on the cross-validation value between each trained model and the data set. We want to see if our models can beat the human radiologists’ positive diagnosis which is round 70%, and to conclude which model works the best for the sample data.   								
							</p>
						</div>


						<ul class="project-wrapper wow animated fadeInUp">
							<li class="portfolio-item">
								<img src="img/portfolio/itema.jpg" class="img-responsive" 
								alt="After having proper input, we can now start feeding data into Decision Tree model. This can be done by importing sklearn package into Jupyter, a python based language.  
								First of all, we split the data set into 75% training set and 25% testing set by applying “train-test-split” function. After this, we simply used “DecisionTreeClassifier()” function to generate a Decision Tree Classifier, and then simply call on the result of this function by using “fit (training_features_input, training_target_input)”. Finally, to show the result graphically, we simply call graphing functions to draw the decision tree.
								With the decision tree constructed, it is very easy to measure the accuracy of this decision tree model by using test set data. The cross-validation score can be calculated by calling function “score( testing_features_input, testing_targets)”. The result we got for this method is 0.735577.								
								">
								<figcaption class="mask">
									<h3>Decision Tree</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="Decision Tree" data-fancybox-group="works" href="img/portfolio/itemla.jpg"><i class="fa fa-search"></i></a></li>
									
								</ul>
							</li>

							<li class="portfolio-item">
								<img src="img/portfolio/item2a.jpg" class="img-responsive" 
								alt="Following the same method as we did for Decision Tree model, we are capable of construct a Random Forest by simply calling function “RandomForestClassifier()” with different number of trees. The cross-validation score in this case can be calculated by first getting the score for each single tree, and then by calculating the mean of trees scores. For 10 trees, we got 0.75405. For 20 trees, we got 0.76614. for 100 trees, we got 0.7590.								
								">
								<figcaption class="mask">
									<h3>Random Forest</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="Random Forest" href="img/portfolio/item2la.jpg" data-fancybox-group="works" ><i class="fa fa-search"></i></a></li>
									
								</ul>
							</li>

							<li class="portfolio-item">
								<img src="img/portfolio/item3a.jpg" class="img-responsive" 
								alt="For k-Nearest-Neighbors model, in the same package “sklearn”, the function “KNeighborsClassifier ()” can be used. And the score of this model can be calculated using the same method as before. 
								The hard part for KNN model is to find the optimal K value. To solve this problem, we looped from K=50 to K=120, we found the optimal K is 103, and the score is 0.80853.								
								">
								<figcaption class="mask">
									<h3>KNN algorithms</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="KNN algorithms" data-fancybox-group="works" href="img/portfolio/item3la.jpg"><i class="fa fa-search"></i></a></li>
									
								</ul>
							</li>

							<li class="portfolio-item">
								<img src="img/portfolio/item4a.jpg" class="img-responsive" 
								alt="To calculate the score of naïve bayes, we import sklearn package. We firstly calculate the min-max of the data and then use the MultinomialNB function to build the model.
								The mean of cross_value score of logistic regression is 0.80736.
								">
								<figcaption class="mask">
									<h3>Naive Bayes</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="Naive Bayes" data-fancybox-group="works" href="img/portfolio/item4la.jpg"><i class="fa fa-search"></i></a></li>
									
								</ul>
							</li>

							<li class="portfolio-item">
								<img src="img/portfolio/item5a.jpg" class="img-responsive" 
								alt="To calculate the score of logistic regression, we import sklearn package. We call the built-in logisticRegression function and then calculate the mean. It’s pretty straightforward.
								The mean of cross_value score of logistic regression is 0.80736.
								">
								<figcaption class="mask">
									<h3>Logistic Regression</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="Logistic Regression" data-fancybox-group="works" href="img/portfolio/item5la.jpg"><i class="fa fa-search"></i></a></li>
									
								</ul>
							</li>

							<li class="portfolio-item">
								<img src="img/portfolio/item6a.jpg" class="img-responsive" 
								alt="We import Keras package to compute the score of neural network. Firstly, we build a sequential model and add different layers. In this case, we find the hidden layer did not improve the performance so we use single layer here. By testing different variable, we find 7-unit input layers work best. So we choose this model.
								Then we create a binary classifier to estimate the score and output the mean score.
								The mean of cross_value of neural network is 0.8012048.								
								">
								<figcaption class="mask">
									<h3>Neural Network</h3>
									<!-- <p>Lorem Ipsum is simply dummy text of the printing and typesetting ndustry. </p> -->
								</figcaption>
								<ul class="external">
									<li><a class="fancybox" title="Neural Network" data-fancybox-group="works" href="img/portfolio/item6la.jpg"><i class="fa fa-search"></i></a></li>
				
								</ul>
							</li>
						</ul>

						<div class="sec-title text-center wow animated fadeInDown">
							<br><br>
							<p style="font-size: 30px !important"><Strong>Suprisingly, decision tree is the worst! </Strong></p><br>
							<p style="font-size: 30px !important"><Strong>Logistic regression and KNN are the best!</Strong></p><br>
					
							<div id="chart"></div>
							<script type="text/javascript" src="https://www.gstatic.com/charts/loader.js"></script>
							<script type="text/javascript">
								google.charts.load("current", {packages:["corechart"]});
								google.charts.setOnLoadCallback(drawChart);
								function drawChart() {
								  var data = google.visualization.arrayToDataTable([
									["Element", "Score", { role: "style" } ],
									["Decision Tree", 0.735577, "#ff4000"],
									["Random Forest",  0.7590, "#0080ff"],
									["KNN", 0.80853, "#80ff00"],
									["Naive Bayes", 0.7844056, "color: #bf00ff"],
									["Logistic Regression", 0.8073584, "color: gold"],
									["Neural Network", 0.8012048, "color: #e5e4e2"]
								  ]);
							
								  var view = new google.visualization.DataView(data);
								  view.setColumns([0, 1,
												   { calc: "stringify",
													 sourceColumn: 1,
													 type: "string",
													 role: "annotation" },
												   2]);
							
								  var options = {
									// title: "In this case, Logistic Regressio and KNN have the best score!",
									width: 700,
									height: 400,
									bar: {groupWidth: "95%"},
									legend: { position: "none" },
								  };
								  var chart = new google.visualization.BarChart(document.getElementById("barchart_values"));
								  chart.draw(view, options);
							  }
							  </script>
							<div id="barchart_values" style="width: 900px; height: 300px; margin-left: 300px">
	
							</div>
						</div>

					</div>
				</div>
			</section>
			<!-- end portfolio section -->



			<!-- real world practice section -->
			<section id="service" class="parallax">
				<div class="container">
					<div class="row">

						<div class="sec-title text-center">
							<h2 class="wow animated bounceInLeft">Real-world Practice</h2>
							<p class="wow animated bounceInRight">how does deep-learning influnce the medical field</p>
						</div>

						<div class="col-md-3 col-sm-6 col-xs-12 text-center wow animated zoomIn">
							<div class="service-item">
								<div class="service-icon">
									<a href="https://www.medscape.com/viewarticle/890003" target="_blank"><i class="fa fa-eye fa-3x"></i></a>
								</div>
	
								<p>Artificial Intelligence Eyed as Diabetic Retinopathy Screen</p>
							</div>
						</div>

						<div class="col-md-3 col-sm-6 col-xs-12 text-center wow animated zoomIn" data-wow-delay="0.3s">
							<div class="service-item">
								<div class="service-icon">
									<a href="http://www.empr.com/news/deep-learning-algorithms-compared-to-pathologists-breast-cancer/article/713726/" target="_blank"><i class="fa fa-medkit fa-3x"></i></a>
								</div>
								<!-- <h3>Well Documented</h3> -->
								<p>Accuracy of Artificial Intelligence Assessed in CA Diagnosis</p>
							</div>
						</div>

						<div class="col-md-3 col-sm-6 col-xs-12 text-center wow animated zoomIn" data-wow-delay="0.6s">
							<div class="service-item">
								<div class="service-icon">
									<a href="https://www.digitaltrends.com/cool-tech/deep-learning-predict-seizure/" target="_blank"><i class="fa fa-headphones fa-3x"></i></a>
								</div>
								<!-- <h3>Design UI/UX</h3> -->
								<p>Deep-learning algorithms help study brain waves to predict seizures </p>
							</div>
						</div>

						<div class="col-md-3 col-sm-6 col-xs-12 text-center wow animated zoomIn" data-wow-delay="0.9s">
							<div class="service-item">
								<div class="service-icon">
									<a href="https://www.nextplatform.com/2017/11/27/medical-imaging-drives-gpu-accelerated-deep-learning-developments/" target="_blank"><i class="fa fa-heart fa-3x"></i></a>
								</div>

								<!-- <h3>Web Security</h3> -->
								<p>Medical Imaging Drives GPU Accelerated Deep Learning Developments </p>
							</div>
						</div>

					</div>
				</div>
			</section>
			<!-- end real world practise section -->

			<!-- Contact section -->
		<section id="testimonials" class="parallax">
        <div class="overlay">
          <div class="container">
            <div class="row">

              <div class="sec-title text-center white wow animated fadeInDown">
                <h2>Conclusion</h2>
              </div>

              <div id="testimonial" class=" wow animated fadeInUp">
                <div class="testimonial-item text-center">
                  <img src="img/member-1.jpg" alt="Us">
                  <div class="clearfix">
                    <p>Before this project, we are completely green-hand about machine learning. After doing this project, we truely learned a lot
						so now we want to share this to everyone. Hope this website can give some inspiration to those students who are instereted in deep learning but 
						do not know where to begin. Hope deep learning can have better future in the medical field.
					</p>
                  </div>
                </div>
              </div>

            </div>
          </div>
        </div>
			</section>
			<!-- end Contact section -->

		</main>

		<footer id="footer">
			<div class="container">
				<div class="row text-center">
					<div class="footer-content">
						<p>Copyright &copy; 2017-2018 Design and Developed By Bill and Lini</a> </p>
					</div>
				</div>
			</div>
		</footer>

		<!-- Essential jQuery Plugins
		================================================== -->
		<!-- Main jQuery -->
        <script src="js/jquery-1.11.1.min.js"></script>
		<!-- Twitter Bootstrap -->
        <script src="js/bootstrap.min.js"></script>
		<!-- Single Page Nav -->
        <script src="js/jquery.singlePageNav.min.js"></script>
		<!-- jquery.fancybox.pack -->
        <script src="js/jquery.fancybox.pack.js"></script>
		<!-- Google Map API -->
		<script src="http://maps.google.com/maps/api/js?sensor=false"></script>
		<!-- Owl Carousel -->
        <script src="js/owl.carousel.min.js"></script>
        <!-- jquery easing -->
        <script src="js/jquery.easing.min.js"></script>
        <!-- Fullscreen slider -->
        <script src="js/jquery.slitslider.js"></script>
        <script src="js/jquery.ba-cond.min.js"></script>
		<!-- onscroll animation -->
        <script src="js/wow.min.js"></script>
		<!-- Custom Functions -->
        <script src="js/main.js"></script>
    </body>
</html>
